---
title: "SEM power analysis"
author: "Marcello Gallucci"
topic: sem
output: pdf_document
bibliography: bib.bib
link-citations: yes
editor_options:
  chunk_output_type: console
category: help
---


```{r echo=FALSE,results='hide'}
library(mcdocs)
mcdocs_init()

```

`r version("0.6.0")`

`r pic("pics/sem/ui.png")`


`SEM power analysis` enables the computation of power parameters (such as required N and power) for a wide range of structural equation models. It can be used to estimate power parameters based on both chi-square constraints and `Monte Carlo` methods.

The module allows users to specify the prospective model using the syntax of the [lavaan R package](https://lavaan.ugent.be/), with some modifications necessary to input the expected parameters. The results are partially obtained using the [semPower R package](https://CRAN.R-project.org/package=semPower), though several solutions are also implemented natively within the module.

:::{ .adm .adm-note}
Important

The capabilities (so far) of the module is to obtain power parameters associated with tests of single coefficients, or combinations of coefficients.

:::

# Input

The crucial aspect of the module usage is to input the expected model. One can start from a lavaan syntax model, such as 

```{r eval=FALSE}

# latent variables 
   ind60 =~ x1 + x2 + x3 
   dem60 =~ y1 + y2 + y3 + y4 
   dem65 =~ y5 + y6 + y7 + y8 
 # regressions
   dem60 ~ ind60 
   dem65 ~ ind60 + dem60 
  # residual correlations
   y1 ~~ y5    

```


To input the expected coefficients, one multiplies each variable for the associated coefficient

```{r eval=FALSE}

# latent variables 
    ind60 =~ .6*x1 + .6*x2 + .6*x3
    dem60 =~ .8*y1 + .8*y2 + .8*y3 + .8*y4
    dem65 =~ .8*y5 + .8*y6 + .8*y7 + .8*y8
  # regressions
    dem60 ~ .3*a*ind60
    dem65 ~  .4*b*ind60 + .2*c*dem60
  # residual correlations
    y1 ~~ .1*y5    

```


In this example, we specify that the latent variable `ind60` should have loadings equal to $0.6$, and both the latent variables `dem60` and `dem65` should have loadings equal to $0.9$. Additionally, the regression coefficients for the latent variables are set to $0.3$, $0.4$, and $0.2$, respectively. The scale of the coefficients should be chosen under the assumption that all observed variables are standardized.

Another requirement is to specify labels for the parameters we wish to test. In this example, we have labeled the three latent variables as $a$, $b$, and $c$, respectively. This allows us to impose constraints on them and compute the required sample size (or power) to obtain a significant test (given a specified $\alpha$) for those particular coefficients or combinations of coefficients. This is achieved by constraining the coefficients to zero.

```{r eval=FALSE}

# latent variables 
    ind60 =~ .6*x1 + .6*x2 + .6*x3
    dem60 =~ .8*y1 + .8*y2 + .8*y3 + .8*y4
    dem65 =~ .8*y5 + .8*y6 + .8*y7 + .8*y8
  # regressions
    dem60 ~ .3*a*ind60
    dem65 ~  .4*b*ind60 + .2*c*dem60
  # residual correlations
    y1 ~~ .1*y5
  # tests
    a == 0
    
```


In this case, we are requesting the power parameter associated with the coefficient $a*ind60 = 0.3$. The module will compute the required parameters to obtain a statistically significant test by comparing two models: one where the coefficient of `ind60` is freely estimated and another where the coefficient of `ind60` is constrained to $0$. In the module, this model looks like this:

`r pic("pics/sem/input.1.1.png")`

After checking the usual input values (Type I error, required power, etc)

`r pic("pics/sem/input.1.2.png")`

# Results

`r pic("pics/sem/output.1.1.png")`


The main table reports the required N to achieve a statistically significant result when testing the `ind60` coefficient. Additionally, we are provided with the path diagram to verify whether the model aligns with our expectations. Admittedly, the path diagram may appear a bit cluttered at times, but its purpose is solely to confirm the model's structure, not to look aesthetically pleasing.

`r pic("pics/sem/output.1.2.png")`

# Multiple tests

It is often the case that a researcher needs to test more than one coefficient in the same model. In our example, for instance, we may want to test both $a$ and $b$, meaning that the power results will depend on both coefficient tests. However, when multiple hypotheses are involved, it is important to carefully distinguish between _omnibus tests_ and _conjunction tests_.

An _omnibus test_ refers to a statistical test that encompasses more than one null hypothesis, yielding a significant result if **any** of the null hypotheses are rejected. In SEM terms, an omnibus test is significant if any of the coefficients are significantly different from zero. For example, in linear models, the omnibus test of $R^2$ becomes significant if the explained variance is significantly different from zero, regardless of whether this variance is explained by one, two, or more terms in the model.

A _conjunction test_, on the other hand, refers to a statistical test that also encompasses multiple null hypotheses but yields a significant result only if **all** null hypotheses are rejected. In SEM terms, a conjunction test is significant only if all coefficients are significantly different from zero.

In PAMLj, both types of tests are available:

- _Omnibus_ tests are specified by listing the coefficients to be tested, each with a separate constraint: $p1==0$, $p2==0$. In our example, assuming we want to test both $a$ and $b$, the code would look like this:


```{r eval=FALSE}

# latent variables 
    ind60 =~ .6*x1 + .6*x2 + .6*x3
    dem60 =~ .8*y1 + .8*y2 + .8*y3 + .8*y4
    dem65 =~ .8*y5 + .8*y6 + .8*y7 + .8*y8
  # regressions
    dem60 ~ .3*a*ind60
    dem65 ~  .4*b*ind60 + .2*c*dem60
  # residual correlations
    y1 ~~ .1*y5
  # tests
    a == 0
    b == 0
    
```

`r pic("pics/sem/output.2.png")`

This code computes the power parameters for testing that **any** coefficients among $a$ and $b$ is significant. As expected, the required N is smaller than in the previous example (where only $a$ was tested), because it is easier —and thus more powerful — to detect any of two significant coefficients than to detect a specific one.

- _Conjunction_ tests are specified by equating all coefficients to be tested and setting them to zero in a single constraint: $p1==p2==0$. In our example, assuming we want to test both $a$ and $b$, the code would look like this:

```{r eval=FALSE}

# latent variables 
    ind60 =~ .6*x1 + .6*x2 + .6*x3
    dem60 =~ .8*y1 + .8*y2 + .8*y3 + .8*y4
    dem65 =~ .8*y5 + .8*y6 + .8*y7 + .8*y8
  # regressions
    dem60 ~ .3*a*ind60
dem65 ~  .4*b*ind60 + .2*c*dem60
  # residual correlations
    y1 ~~ .1*y5
  # tests
    a == b == 0
    
```

This code computes the power parameters for testing that **both** coefficients $a$ and $b$ are significant. As expected, the required N is much larger than in the previous examples because it is more difficult—and thus requires more power—to detect both coefficients as significant compared to detecting just one or either of the two.

`r pic("pics/sem/output.3.png")`


# Options

## `r opt_panel("Main")`

`r opt_label("Parameters")`

`r panel_options('pamlsem','power_parameters')`

`r opt_label("Model Method & Options")`

`r panel_options('pamlsem','model_options')`

## `r opt_panel("Sensitivity Analysis")`

Sensitivity analysis, which explores different plots of possible parameter combinations, can be conducted as in any other `r modulename()` sub-module. Please visit the `r link_pages(nickname="sensitivity")` page for more details. For the SEM sub-module, sensitivity analysis is available only for varying N values. When the Monte Carlo method is selected, sensitivity analysis is performed using the analytic method; otherwise, the computation time would be extremely long.


## `r opt_panel("Power Parameters plot")`

```{r child_sensitivity_link, child='commons/powerplot_chunk.Rmd'}
```



## `r opt_panel("Options")`

`r panel_options('pamlsem','panel_options',labels=T)`



`r backto()`

`r issues()`
